


import pandas as pd

departments_df = pd.read_csv("../data/clean/all_depts.csv")

display(departments_df.head())
display(departments_df.shape)
display(departments_df.dtypes)

# dummy column adds comma to the one original column to import better.





import pandas as pd

customers = pd.read_csv("../data/clean/customers_for_import.csv")

display(customers.head())
display(customers.shape)
display(customers.dtypes)

# dummy column adds comma to the one original column to import better.





import pandas as pd

agents = pd.read_csv("../data/clean/agents.csv")

display(agents.head())
display(agents.shape)
display(agents.dtypes)





import pandas as pd

calls = pd.read_csv("../data/clean/calls.csv")

display(calls.head())
display(calls.shape)
display(calls.dtypes)


import pandas as pd
import numpy as np

# Load agents and calls data
agents = pd.read_csv("../data/clean/agents.csv")
calls = pd.read_csv("../data/clean/calls.csv")

# Step 1: Get the valid agent_id's from the agents DataFrame
valid_agent_ids = agents['agent_id'].tolist()

# Step 2: Identify invalid agent_ids in the calls DataFrame (those not in agents)
invalid_agent_ids = calls[~calls['agent_id'].isin(valid_agent_ids)]['agent_id'].drop_duplicates()

# Print out invalid agent_ids to inspect if necessary
print("Invalid agent_ids in calls DataFrame:")
print(invalid_agent_ids)

# Step 3: Replace invalid agent_ids with a valid agent_id from the agents table
# We replace invalid agent_ids randomly or you can decide how to replace (e.g., using a default valid id)
calls['agent_id'] = np.where(
    calls['agent_id'].isin(valid_agent_ids),
    calls['agent_id'],  # keep valid ids as is
    np.random.choice(valid_agent_ids, size=len(calls))  # replace invalid ids
)

# Step 4: Verify the update
print(calls.head())

# Optionally save the fixed 'calls' DataFrame back to a CSV if needed
calls.to_csv("../data/clean/calls_fixed.csv", index=False)



unmatched = calls[~calls['agent_id'].isin(agents['agent_id'])]
print(unmatched[['agent_id']].drop_duplicates())



# TESTING SQL CODE.
import pandas as pd

# Load the calls data
calls = pd.read_csv("../data/clean/calls_fixed.csv")

# Ensure call_duration is numeric
calls['call_duration'] = pd.to_numeric(calls['call_duration'], errors='coerce')

# Define the bucket counts
total_calls = len(calls)
range_1_30 = ((calls['call_duration'] >= 1) & (calls['call_duration'] <= 30)).sum()
range_31_60 = ((calls['call_duration'] >= 31) & (calls['call_duration'] <= 60)).sum()
range_61_90 = ((calls['call_duration'] >= 61) & (calls['call_duration'] <= 90)).sum()
range_91_120 = ((calls['call_duration'] >= 91) & (calls['call_duration'] <= 120)).sum()
range_120_plus = (calls['call_duration'] > 120).sum()

# Create a summary
summary = {
    'total_calls': total_calls,
    '1-30 min': range_1_30,
    '31-60 min': range_31_60,
    '61-90 min': range_61_90,
    '91-120 min': range_91_120,
    '120+ min': range_120_plus
}

# Display the summary as a DataFrame
summary_df = pd.DataFrame([summary])
print(summary_df)




import pandas as pd

# Load the calls data
calls = pd.read_csv("../data/clean/calls_fixed.csv")

# Define chunk size (e.g., 5000 rows per chunk)
chunk_size = 5000

# Create chunks of the DataFrame
chunks = [calls[i:i + chunk_size] for i in range(0, len(calls), chunk_size)]

# Process each chunk (you can import them one by one)
for i, chunk in enumerate(chunks):
    # Save each chunk as a separate CSV (or directly import to the database)
    chunk.to_csv(f"calls_chunk_{i}.csv", index=False)
    print(f"Processed chunk {i + 1}/{len(chunks)}")






import pandas as pd

abandonments = pd.read_csv("../data/clean/call_abandonment.csv")

display(abandonments.head())
display(abandonments.shape)
display(abandonments.dtypes)


abandonments['abandoned'].sum()
# counts how many calls were abandoned.


import pandas as pd

# Load the datasets
abandonments = pd.read_csv("../data/clean/call_abandonment.csv")
calls = pd.read_csv("../data/clean/calls_fixed.csv")

# Check for matches between call_id and customer_id in both datasets
matched = abandonments.merge(calls, on=['call_id', 'customer_id'], how='inner')

# Check how many matched records there are
print(f"Matched rows: {len(matched)}")

# Check for any unmatched customer_id or call_id
unmatched_abandonments = abandonments[~abandonments['call_id'].isin(calls['call_id']) | ~abandonments['customer_id'].isin(calls['customer_id'])]

# Display unmatched pairs
print(f"Unmatched abandonment records:\n{unmatched_abandonments}")



import pandas as pd
import numpy as np

# Load data
abandonments = pd.read_csv("../data/clean/call_abandonment.csv")
calls = pd.read_csv("../data/clean/calls_fixed.csv")

# Get valid call_id and customer_id pairs
valid_pairs = calls[['call_id', 'customer_id']].dropna()

# Sample new valid pairs (same number as in abandonments)
sampled_pairs = valid_pairs.sample(n=len(abandonments), replace=True).reset_index(drop=True)

# Replace call_id and customer_id in abandonments
abandonments['call_id'] = sampled_pairs['call_id']
abandonments['customer_id'] = sampled_pairs['customer_id']

# Save fixed version
abandonments.to_csv("../data/clean/call_abandonment_fixed.csv", index=False)

print("✅ Fixed call_abandonment.csv — all IDs now match calls_fixed.csv.")



abandonments_fixed = pd.read_csv("../data/clean/call_abandonment_fixed.csv")
display(abandonments_fixed.head())
display(abandonments_fixed.info())


import pandas as pd

# Load the CSV
abandonments = pd.read_csv("../data/clean/call_abandonment_fixed.csv")

# 1. Fix 'call_duration_before_abandonment_(mins)' column
# Convert to integers (rounding if needed), handle NaN values
abandonments['call_duration_before_abandonment_(mins)'] = abandonments['call_duration_before_abandonment_(mins)'].apply(pd.to_numeric, errors='coerce')
abandonments['call_duration_before_abandonment_(mins)'] = abandonments['call_duration_before_abandonment_(mins)'].fillna(0)  # Change NaN to 0
abandonments['call_duration_before_abandonment_(mins)'] = abandonments['call_duration_before_abandonment_(mins)'].apply(lambda x: round(x) if pd.notna(x) else 0)

# 2. Ensure 'abandoned' column is of type string ("True"/"False")
abandonments['abandoned'] = abandonments['abandoned'].apply(lambda x: 'True' if x else 'False')

# 3. Save the cleaned data to the same CSV file (overwrite the original)
abandonments.to_csv("../data/clean/call_abandonment_fixed_2.csv", index=False)

# Display cleaned data to verify
display(abandonments.head())
display(abandonments.info())



print(abandonments['abandoned'].unique())





import pandas as pd

escalations = pd.read_csv("../data/clean/escalations.csv")

display(escalations.head())
display(escalations.shape)
display(escalations.dtypes)


import pandas as pd

# Load data
escalations = pd.read_csv("../data/clean/escalations.csv")
customers = pd.read_csv("../data/clean/customers_for_import.csv")
agents = pd.read_csv("../data/clean/agents.csv")

# Check how many customer_ids and agent_ids are valid
valid_customer_ids = set(customers['customer_id'])
valid_agent_ids = set(agents['agent_id'])

# Filter escalations with valid customer and agent IDs
valid_escalations = escalations[
    escalations['customer_id'].isin(valid_customer_ids) &
    escalations['agent_id'].isin(valid_agent_ids)
]

# Show how many were kept
print(f"✅ Kept {len(valid_escalations)} valid rows out of {len(escalations)} in escalations.csv")

# Save cleaned version
valid_escalations.to_csv("../data/clean/escalations_fixed.csv", index=False)



import pandas as pd
import numpy as np

# Load files
escalations = pd.read_csv("../data/clean/escalations.csv")
customers = pd.read_csv("../data/clean/customers_for_import.csv")
agents = pd.read_csv("../data/clean/agents.csv")

# Sample valid customer_ids and agent_ids
sampled_customer_ids = customers['customer_id'].sample(n=len(escalations), replace=True).reset_index(drop=True)
sampled_agent_ids = agents['agent_id'].sample(n=len(escalations), replace=True).reset_index(drop=True)

# Replace in escalations
escalations['customer_id'] = sampled_customer_ids
escalations['agent_id'] = sampled_agent_ids

# Save to new CSV
escalations.to_csv("../data/clean/escalations_fixed.csv", index=False)

print("✅ Fixed escalations.csv — all customer_id and agent_id values now match your reference tables.")

escalations_2 = pd.read_csv("../data/clean/escalations_fixed.csv")
display(escalations_2.head())





import pandas as pd

csat = pd.read_csv("../data/clean/csat.csv")

display(csat.head())
display(csat.shape)
display(csat.dtypes)


import pandas as pd

# Load the data
csat = pd.read_csv("../data/clean/csat.csv")
customers = pd.read_csv("../data/clean/customers_for_import.csv")
agents = pd.read_csv("../data/clean/agents.csv")

# Check for matches in customer_id
matched_customers = csat[csat['customer_id'].isin(customers['customer_id'])]

# Check for matches in agent_id
matched_agents = csat[csat['agent_id'].isin(agents['agent_id'])]

# Results
print(f"✅ Matched customer_id in csat with customers: {len(matched_customers)}")
print(f"✅ Matched agent_id in csat with agents: {len(matched_agents)}")

# If needed, save the matched CSAT to a new CSV
csat.to_csv("../data/clean/csat_fixed.csv", index=False)



import pandas as pd

# Load the data
csat = pd.read_csv("../data/clean/csat.csv")
customers = pd.read_csv("../data/clean/customers_for_import.csv")
agents = pd.read_csv("../data/clean/agents.csv")

# Sample valid customer_ids and agent_ids
sampled_customer_ids = customers['customer_id'].sample(n=len(csat), replace=True).reset_index(drop=True)
sampled_agent_ids = agents['agent_id'].sample(n=len(csat), replace=True).reset_index(drop=True)

# Replace customer_id and agent_id in csat
csat['customer_id'] = sampled_customer_ids
csat['agent_id'] = sampled_agent_ids

# Save to new CSV
csat.to_csv("../data/clean/csat_fixed.csv", index=False)

print("✅ Fixed csat.csv — all customer_id and agent_id values now match your reference tables.")




